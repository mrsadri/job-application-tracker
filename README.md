# üéØ Job Application Tracker

A modern, feature-rich web application to help you organize and track your job applications. Built with vanilla JavaScript, this tool includes an intelligent job crawler that aggregates positions from multiple sources.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Version](https://img.shields.io/badge/version-1.0.0-green.svg)

## ‚ú® Features

### Three Strategic Approaches

The Job Application Tracker is built around three complementary job search strategies:

#### üéØ Strategy 1: Enhanced Application Process & Learning
- **HR Contact Management**: Store and track HR email addresses and contact information
- **Rejection Email Analysis**: Log and analyze rejection emails to identify patterns
- **Cover Letter Management**: Store, version, and reuse effective cover letters
- **Process Logging**: Detailed step-by-step tracking of each application journey
- **Learning Analytics**: Data-driven insights to improve application success rates
- **Source Effectiveness Tracking**: Identify which job sources yield best results

#### ü§ù Strategy 2: Network Building & Recruiter Management
- **Recruiter Database**: Comprehensive contact management for recruiters and agencies
- **Interaction Tracking**: Log all communications with recruiters and hiring managers
- **Hiring Manager Contacts**: Build and maintain relationships with decision-makers
- **Networking Activity Log**: Track coffee chats, events, and professional connections
- **AI Job Adviser**: ChatGPT-powered task management and personalized guidance
- **Relationship Analytics**: Identify most effective contacts and prioritize relationships

#### üì± Strategy 3: LinkedIn Presence & Personal Branding
- **Content Planning**: Plan and schedule LinkedIn articles and posts
- **Activity Tracking**: Log all LinkedIn activities with engagement metrics
- **Portfolio Management**: Showcase college activities, projects, and achievements
- **Profile View Tracking**: Monitor who views your profile and follow up
- **Engagement Analytics**: Understand what content resonates with your audience
- **Content Calendar**: Maintain consistent presence with scheduled content
- **Inbound Opportunity Tracking**: Log when companies approach you directly
- **AI Weekly Task Management**: ChatGPT-powered weekly task lists for LinkedIn presence building

> **Note**: Strategy features (US-038 to US-057) are defined and ready for implementation. See [STRATEGIES_IMPLEMENTATION_PLAN.md](./STRATEGIES_IMPLEMENTATION_PLAN.md) for detailed implementation roadmap.

### Frontend Application
- ‚úÖ **Track Applications**: Add, edit, and delete job applications with detailed information
- üìä **Statistics Dashboard**: Real-time stats showing your application progress
- üîç **Advanced Filtering**: Search and filter by company, position, status, and source
- üìù **Change History**: Track all modifications to your applications over time
- üíæ **Local Storage**: All data saved securely in your browser
- üì± **Fully Responsive**: Works perfectly on desktop, tablet, and mobile devices
- ‚ôø **Accessible**: WCAG AA compliant with screen reader support
- üé® **Modern UI**: Beautiful interface with smooth animations

### Job Discovery
- üîç **Multi-source Aggregation**: Integrates with Remotive, Arbeitnow, GitHub Jobs, and more
- üéØ **Smart Filtering**: Only shows jobs matching your profile preferences
- üîÑ **Auto-deduplication**: Removes duplicate job postings
- üìÖ **Recent Jobs**: Filters to jobs posted in the last 2 weeks
- üìä **Relevance Scoring**: Jobs scored based on your profile (roles, skills, locations)
- üöÄ **Real-time Fetching**: Click "Update Jobs" to fetch latest opportunities

### Backend Crawler Service (Optional)
- üîç **Enhanced Sources**: Backend crawler supports Adzuna, Indeed, LinkedIn (via SerpAPI), and Reed
- ü§ñ **Respectful Crawling**: Follows robots.txt and implements rate limiting
- üöÄ **RESTful API**: Easy integration with the frontend
- üì¶ **Deployable**: Can be deployed to Railway, Heroku, Vercel, or similar platforms

## üöÄ Quick Start

### Option 1: Use Frontend Only (Simplest)

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/job-application-tracker.git
   cd job-application-tracker
   ```

2. **Open in browser**
   - Simply open `index.html` in your web browser
   - Or use a local server (recommended):
   ```bash
   # Using Python 3
   python3 -m http.server 8080
   
   # Using Node.js
   npx http-server -p 8080
   ```

3. **Visit** `http://localhost:8080`

That's it! The app works without any backend. Job suggestions fetch real jobs from free public APIs (Remotive, Arbeitnow, GitHub Jobs).

### Option 2: With Job Crawler (Full Features)

To enable automatic job searching from multiple sources:

1. **Set up the crawler backend**
   ```bash
   cd crawler
   npm install
   cp .env.example .env
   # Edit .env with your API keys (optional)
   npm start
   ```

2. **Open the frontend**
   - In a new terminal:
   ```bash
   cd ..
   python3 -m http.server 8080
   ```

3. **Visit** `http://localhost:8080`

The frontend will automatically connect to the crawler API on port 3000.

## üìã Detailed Setup

### Prerequisites

**For Frontend Only:**
- Modern web browser (Chrome, Firefox, Safari, Edge)
- Optional: Local web server (Python, Node.js, or similar)

**For Crawler Service:**
- Node.js 18+ 
- npm or yarn

### Frontend Configuration

1. **Copy your profile template**
   ```bash
   cp my-profile.example.json my-profile.json
   ```

2. **Edit** `my-profile.json` with your details:
   ```json
   {
     "name": "Your Name",
     "target_locations": ["Dublin, Ireland", "Amsterdam, Netherlands"],
     "preferred_roles": ["Product Designer", "UX Designer"],
     "skills": ["Product Design", "Figma", "JavaScript"]
   }
   ```

### Crawler Configuration (Optional)

1. **Navigate to crawler directory**
   ```bash
   cd crawler
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Configure environment**
   ```bash
   cp .env.example .env
   ```

4. **Get API keys** (optional, but recommended for better results):

   - **Adzuna** (Free - 1000 requests/month)
     - Sign up at https://developer.adzuna.com/
     - Add `ADZUNA_APP_ID` and `ADZUNA_APP_KEY` to `.env`
   
   - **SerpAPI** (For LinkedIn and enhanced Indeed)
     - Sign up at https://serpapi.com/
     - Add `SERPAPI_KEY` to `.env`
   
   - **Reed** (UK jobs)
     - Sign up at https://www.reed.co.uk/developers
     - Add `REED_API_KEY` to `.env`

5. **Start the server**
   ```bash
   npm start
   ```

   The crawler API will be available at `http://localhost:3000`

## üìñ Usage Guide

### Adding Applications

1. Click "**+ Add New Application**" button
2. Fill in the form with job details:
   - Company name (required)
   - Position/Title (required)
   - Location (select from dropdown)
   - Job URL (optional)
   - Application date (required)
   - Status (Applied, Interview, Rejected, Accepted)
   - Notes, contact person, and source
3. Click "**Save Application**"

### Managing Applications

- **Edit**: Click the "Edit" button on any job card
- **Delete**: Click the "Delete" button to remove an application
- **View History**: Click "Change History" to see all modifications
- **Filter**: Use the sidebar to search and filter applications
- **Sort**: Sort by application date or status update date

### Finding Suggested Jobs

1. Ensure your `my-profile.json` is configured
2. Click "**üîÑ Update Jobs**" in the Suggested Jobs section
3. Review the suggested jobs matching your profile
4. Click actions:
   - **View Job ‚Üí**: Opens the job posting in a new tab
   - **‚úì Apply**: Marks as applied and adds to your applications
   - **‚óã Save for Later**: Bookmarks for future review
   - **‚úó Decline**: Hides the job

## üé® Features in Detail

### Application Statuses

- **Applied** (‚óã): Initial application submitted
- **Interview** (‚óê): Invited for interview or in interview process
- **Rejected** (‚úï): Application was not successful
- **Accepted** (‚úì): Job offer received! üéâ

### Filters and Search

- **Search**: Find applications by company name, position, or location
- **Status Filter**: Show only applications with specific status
- **Source Filter**: Filter by where you found the job (LinkedIn, Telegram channels, etc.)
- **Sort Options**: 
  - Application Date (newest/oldest first)
  - Status Update Date (recent/oldest first)

### Change History

Every application tracks:
- When it was created
- All field changes with before/after values
- Timestamps for each modification

### Keyboard Shortcuts

- `Ctrl/Cmd + N`: Add new application
- `Ctrl/Cmd + K`: Focus search bar
- `Esc`: Close modals or mobile menu

### Mobile Support

- Responsive design adapts to all screen sizes
- Mobile menu for easy navigation on small screens
- Touch-optimized buttons (44px minimum touch target)
- Swipe-friendly interface

## üåê Deployment Status

‚úÖ **Live Application**: https://mrsadri.github.io/job-application-tracker/

The application is successfully deployed to GitHub Pages and fully functional in production.

### Deploy to GitHub Pages (Frontend)

1. **Push to GitHub**
   ```bash
   git add .
   git commit -m "Initial commit"
   git branch -M main
   git remote add origin https://github.com/yourusername/job-application-tracker.git
   git push -u origin main
   ```

2. **Enable GitHub Pages**
   - Go to your repository on GitHub
   - Settings ‚Üí Pages
   - Source: Deploy from branch `main`
   - Folder: `/ (root)`
   - Click Save

3. **Access your site** at `https://yourusername.github.io/job-application-tracker`

**Note**: The application is already deployed and accessible at the live URL above.

### Deploy Crawler Service

The crawler needs a backend server. Options:

1. **Heroku**
   ```bash
   cd crawler
   heroku create your-app-name
   git push heroku main
   ```

2. **Vercel** (with serverless functions)
   ```bash
   npm install -g vercel
   vercel
   ```

3. **Railway**
   - Connect your GitHub repository
   - Configure environment variables
   - Deploy

4. **VPS/Cloud Server**
   ```bash
   # On your server
   git clone your-repo
   cd crawler
   npm install
   npm start
   # Use PM2 or similar for process management
   ```

After deploying the crawler, update the frontend's API URL in `job-api-config.js`:
```javascript
window.CRAWLER_API_URL = 'https://your-crawler-api.com/api/crawl';
```

## üìö Documentation

- **[QUICK_START.md](QUICK_START.md)** - 5-minute getting started guide
- **[CRAWLER_SETUP.md](CRAWLER_SETUP.md)** - Detailed crawler configuration
- **[crawler/README.md](crawler/README.md)** - Crawler API documentation
- **[GPT_AGENT_SETUP_GUIDE.md](GPT_AGENT_SETUP_GUIDE.md)** - AI assistant setup
- **[ACCESSIBILITY_IMPROVEMENTS.md](ACCESSIBILITY_IMPROVEMENTS.md)** - Accessibility features
- **[USER_STORIES.md](USER_STORIES.md)** - User stories and use cases (72 stories including Phase 1 vision and 3 strategic approaches)
- **[PROJECT_BRIEF.md](PROJECT_BRIEF.md)** - Complete project brief with Phase 1 vision, architecture, and success criteria
- **[STRATEGIES_IMPLEMENTATION_PLAN.md](STRATEGIES_IMPLEMENTATION_PLAN.md)** - Detailed implementation plan for Strategy 1, 2, and 3 features
- **[PROJECT_SUMMARY.md](PROJECT_SUMMARY.md)** - Comprehensive project overview and status
- **[IMPLEMENTATION_STATUS.md](IMPLEMENTATION_STATUS.md)** - Current implementation status of all features

## üõ†Ô∏è Technology Stack

**Frontend:**
- HTML5
- CSS3 (with CSS Variables)
- Vanilla JavaScript (ES6+)
- LocalStorage API

**Backend (Crawler):**
- Node.js 18+
- Express.js
- Axios for HTTP requests
- Cheerio for HTML parsing
- Puppeteer for JavaScript-rendered pages
- node-cron for scheduling

## üîí Privacy & Data

- All application data is stored locally in your browser
- No data is sent to external servers (unless you use the crawler)
- Crawler API only processes job search queries
- Your profile data stays on your device

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Job search APIs: Adzuna, Reed, SerpAPI
- Icons: Native emoji support
- Inspiration: Personal job search experiences

## üìß Contact

**Masih Sadri**
- Portfolio: [https://mrsadri.github.io/Portfolio/](https://mrsadri.github.io/Portfolio/)
- GitHub: [@yourusername](https://github.com/yourusername)

## üîÆ Future Enhancements

Potential features for future versions:
- [ ] Export/Import functionality (CSV/JSON)
- [ ] Email reminders for follow-ups
- [ ] Interview preparation tools
- [ ] Salary comparison charts
- [ ] Application timeline visualization
- [ ] Browser extension
- [ ] Mobile app (React Native)
- [ ] Cloud sync (optional)

---

**Good luck with your job search!** üçÄüéâ

If you find this project helpful, please give it a ‚≠ê on GitHub!
